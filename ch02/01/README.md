# LLM 分词器构建流程

这是一个完整的 LLM 分词器实现，包含 6 个步骤，从文件下载到分词器测试。

## 📁 文件结构

```
ch02/01/
├── generate_file.py          # 步骤 1: 下载/生成 the-verdict.txt
├── read_file.py              # 步骤 2: 读取文件内容
├── tokenization.py           # 步骤 3: 分词处理
├── create_vocab.py           # 步骤 4: 创建词汇表
├── tokenizer_class.py        # 步骤 5: 实现分词器类
├── main.py                   # 步骤 6: 主程序（执行完整流程）
└── README.md                 # 本文档
```

## 🚀 快速开始

### 执行完整流程（推荐）

```bash
python main.py
```

这将自动执行步骤 1-6，包括：
- ✅ 下载训练文本
- ✅ 读取并分词
- ✅ 创建词汇表
- ✅ 构建分词器
- ✅ 测试验证

### 单独执行各步骤

你也可以单独执行每个步骤进行调试或学习：

```bash
# 步骤 1: 下载文件
python generate_file.py

# 步骤 2: 读取文件
python read_file.py

# 步骤 3: 分词
python tokenization.py

# 步骤 4: 创建词汇表
python create_vocab.py

# 步骤 5: 测试分词器类
python tokenizer_class.py
```

## 📊 输出示例

运行 `main.py` 后的输出：

```
🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀
               LLM 分词器完整流程
          执行步骤 1-6：从文件生成到分词器测试
🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀

======================================================================
  步骤 1: 生成/下载文件
======================================================================
✓ 文件已存在: the-verdict.txt
✓ 步骤 1 完成: 文件已准备好

======================================================================
  步骤 2: 读取文件内容
======================================================================
✓ 文件读取成功！
  文件大小: 20479 字符
✓ 步骤 2 完成: 文本已读取 (20479 字符)

======================================================================
  步骤 3: 分词处理
======================================================================
✓ 分词完成！
  总 token 数: 4690
✓ 步骤 3 完成: 获得 4690 个 tokens

======================================================================
  步骤 4: 创建词汇表
======================================================================
✓ 词汇表创建成功！
  词汇表大小: 1130 个唯一 tokens
✓ 步骤 4 完成: 词汇表包含 1130 个唯一 tokens

======================================================================
  步骤 5: 初始化分词器
======================================================================
✓ 分词器初始化完成
  词汇表大小: 1130
✓ 步骤 5 完成: 分词器已创建

======================================================================
  步骤 6: 测试分词器
======================================================================

[测试 1] 基本编码解码
✓ 编码完成
✓ 解码完成

[测试 2] 训练文本句子处理
✓ Token 数量: 17

[测试 3] 词汇表统计
  总 token 数: 4690
  唯一 token 数: 1130
  平均 token 长度: 3.57 字符

======================================================================
  ✨ 所有步骤完成！
======================================================================

📊 总结:
  • 文件: the-verdict.txt
  • 文本大小: 20479 字符
  • Token 总数: 4690
  • 词汇表大小: 1130
  • 分词器: SimpleTokenizerV1

🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉
```

## 🔧 技术细节

### 分词策略

使用正则表达式进行分词：

```python
import re
preprocessed = re.split(r'([,.:;?_!"()\']|--|\s)', raw_text)
```

**说明：**
- `[,.:;?_!"()\']` - 匹配常见标点符号
- `|--` - 匹配双连字符
- `|\s` - 匹配空白字符
- 使用捕获组 `(...)` 保留分隔符

### 词汇表构建

```python
# 1. 去重并排序
all_words = sorted(list(set(tokens)))

# 2. 创建 {token: id} 映射
vocab = {token: integer for integer, token in enumerate(all_words)}
```

### SimpleTokenizerV1 类

提供两个核心方法：

**`encode(text)`** - 文本 → 整数 ID 序列
```python
tokenizer = SimpleTokenizerV1(vocab)
ids = tokenizer.encode("Hello, world!")
# 输出: [123, 456, 789]
```

**`decode(ids)`** - 整数 ID 序列 → 文本
```python
text = tokenizer.decode([123, 456, 789])
# 输出: "Hello, world!"
```

## ⚠️ 注意事项

### 1. 词汇表限制

V1 版分词器**不支持未知词**（OOV - Out of Vocabulary）：

```python
# ❌ 会报错
tokenizer.encode("Hello")  # 如果 "Hello" 不在词汇表中

# ✅ 解决方案
# 使用训练文本中的词
tokenizer.encode("I HAD always thought Jack Gisburn")
```

### 2. 分词特点

- 保留标点符号作为独立 token
- `--` 作为单独的 token
- 缩写如 `It's` 会被分成 `It'` 和 `s`

### 3. 模块命名

为了避免与 Python 标准库冲突：
- ❌ `tokenize.py` → ✅ `tokenization.py`

## 📚 学习资源

- [LLMs from Scratch](https://github.com/rasbt/LLMs-from-scratch)
- [Python 正则表达式](https://docs.python.org/3/library/re.html)
- [Python 字符串方法](https://docs.python.org/3/library/stdtypes.html#string-methods)

## 🎯 下一步

1. **改进分词器**
   - 添加特殊 token（如 `<UNK>`, `<PAD>`, `<EOS>`）
   - 支持未知词处理
   - 实现 BPE（Byte Pair Encoding）算法

2. **优化性能**
   - 使用更高效的数据结构
   - 添加批处理功能
   - 支持多线程处理

3. **扩展功能**
   - 添加字符级分词
   - 支持子词分词（Subword Tokenization）
   - 集成到实际 LLM 训练流程

## 📝 版本历史

- **v1.0** (2026-01-04)
  - 初始版本
  - 实现基础的分词器功能
  - 支持编码和解码

---

**祝学习愉快！** 🎓
